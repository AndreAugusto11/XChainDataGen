{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"cctp\", \"ccip\", \"stargate_oft\", \"stargate_bus\", \"across\", \"ronin\", \"polygon\", \"polygon_plasma\", \"omnibridge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(bridge):\n",
    "    # Connect to the SQLite database\n",
    "    engine = create_engine(f'postgresql+psycopg2://admin:pwd@localhost:5432/{bridge}')\n",
    "    conn = engine.connect()\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_name):\n",
    "    conn = connect(dataset_name.split(\"_\")[0] if \"_\" in dataset_name else dataset_name)\n",
    "    query = f\"SELECT * FROM {dataset_name}_cross_chain_transactions\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_token_metadata(dataset_name):\n",
    "    conn = connect(dataset_name.split(\"_\")[0] if \"_\" in dataset_name else dataset_name)\n",
    "    query = f\"SELECT * FROM token_metadata\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_eth_price():\n",
    "    conn = connect(\"across\")\n",
    "    query = f\"SELECT * FROM token_price where name = 'Wrapped Ether'\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Total size:  2021\n",
      "Finished. Total size:  1283\n"
     ]
    }
   ],
   "source": [
    "df_token_metadata = pd.DataFrame()\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    df = get_token_metadata(dataset_name)\n",
    "\n",
    "    # append all data in one dataframe\n",
    "    df_token_metadata = pd.concat([df_token_metadata, pd.DataFrame(df)], ignore_index=True)\n",
    "\n",
    "print(\"Finished. Total size: \", len(df_token_metadata))\n",
    "\n",
    "# remove duplicates based on symbol, name, blockchain, address\n",
    "df_token_metadata = df_token_metadata.drop_duplicates(subset=['symbol', 'name', 'blockchain', 'address'])\n",
    "\n",
    "print(\"Finished. Total size: \", len(df_token_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1s = [\"ethereum\", \"bnb\", \"avalanche\"]\n",
    "L2s = [\"arbitrum\", \"optimism\", \"base\", \"scroll\", \"linea\"]\n",
    "\n",
    "def add_blockchain_types(df):\n",
    "    for i, row in df.iterrows():\n",
    "        src_blockchain = row['src_blockchain']\n",
    "        dst_blockchain = row['dst_blockchain']\n",
    "\n",
    "        if src_blockchain in L1s:\n",
    "            df.at[i, 'src_blockchain_type'] = \"L1\"\n",
    "\n",
    "        elif src_blockchain in L2s:\n",
    "            df.at[i, 'src_blockchain_type'] = \"L2\"\n",
    "\n",
    "        else:\n",
    "            df.at[i, 'src_blockchain_type'] = \"sidechain\"\n",
    "\n",
    "        if dst_blockchain in L1s:\n",
    "            df.at[i, 'dst_blockchain_type'] = \"L1\"\n",
    "\n",
    "        elif dst_blockchain in L2s:\n",
    "            df.at[i, 'dst_blockchain_type'] = \"L2\"\n",
    "\n",
    "        else:\n",
    "            df.at[i, 'dst_blockchain_type'] = \"sidechain\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cctx_latency(df):\n",
    "    # Calculate latency\n",
    "    df['latency'] = df['dst_timestamp'] - df['src_timestamp']\n",
    "    return df\n",
    "\n",
    "def add_stargate_bus_latency(df):\n",
    "    df['latency'] = df['dst_timestamp'] - df['user_timestamp']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate CCTX User and Operator Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_and_operator_cost(bridge, df):\n",
    "    # First, we need to adjust the cost of issuing a transaction on the source chain and the destination chain\n",
    "    # This is done to account for the fact that the cost of a transaction is shared among multiple cross-chain transactions\n",
    "    src_txs_count = df['src_transaction_hash'].value_counts()\n",
    "    dst_txs_count = df['dst_transaction_hash'].value_counts()\n",
    "\n",
    "    df['adjusted_src_fee_usd'] = df['src_fee_usd'] / df['src_transaction_hash'].map(src_txs_count)\n",
    "    df['adjusted_dst_fee_usd'] = df['dst_fee_usd'] / df['dst_transaction_hash'].map(dst_txs_count)\n",
    "\n",
    "    # Now, we add two new columns to represent the cost for the user and for the operator\n",
    "    # and we calculate the cost for each bridge separately based on its internal logic \n",
    "\n",
    "    df['user_cost'] = df['adjusted_src_fee_usd']\n",
    "    df['operator_cost'] = df['adjusted_dst_fee_usd']\n",
    "\n",
    "    ## Across\n",
    "    if bridge == 'across':\n",
    "        df['user_cost'] += (\n",
    "            df['input_amount_usd'] - df['output_amount_usd']\n",
    "        ).fillna(0)\n",
    "\n",
    "    ## CCIP\n",
    "    if bridge == 'ccip':\n",
    "        df['user_cost'] += df['fee_token_amount_usd'].fillna(0)\n",
    "\n",
    "    ## Sidechains (Polygon, Ronin, Omnibridge)\n",
    "    if bridge in ['polygon', 'ronin', 'omnibridge']:\n",
    "        df['operator_cost'] += df.loc[\n",
    "            df['dst_blockchain'] != 'ethereum', 'adjusted_dst_fee_usd'\n",
    "        ].fillna(0)\n",
    "\n",
    "        df['user_cost'] += df.loc[\n",
    "            df['dst_blockchain'] == 'ethereum', 'adjusted_dst_fee_usd'\n",
    "        ].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_and_operator_cost_stargate_bus(df):\n",
    "    # We deal with Stargate Bus separately because there are two transactions on the source chain: user and bus\n",
    "\n",
    "    src_txs_count = df['user_transaction_hash'].value_counts()\n",
    "    dst_txs_count = df['dst_transaction_hash'].value_counts()\n",
    "\n",
    "    df['adjusted_user_fee_usd'] = df['user_fee_usd'] / df['user_transaction_hash'].map(src_txs_count)\n",
    "    df['adjusted_dst_fee_usd'] = df['dst_fee_usd'] / df['dst_transaction_hash'].map(dst_txs_count)\n",
    "\n",
    "    df['operator_cost'] = df['adjusted_dst_fee_usd']\n",
    "\n",
    "    # We also need to adjust the cost of the executor fee, the DVN fee, and the bus fee when the bridge is Stargate Bus\n",
    "    # This is done to account for the fact that the cost of these fees is shared among multiple cross-chain transactions that share the bus\n",
    "    bus_txs_count = df['bus_transaction_hash'].value_counts()\n",
    "\n",
    "    df['adjusted_executor_fee_usd'] = df['executor_fee_usd'] / df['bus_transaction_hash'].map(bus_txs_count)\n",
    "    df['adjusted_dvn_fee_usd'] = df['dvn_fee_usd'] / df['bus_transaction_hash'].map(bus_txs_count)\n",
    "    df['adjusted_bus_fee_usd'] = df['bus_fee_usd'] / df['bus_transaction_hash'].map(bus_txs_count)\n",
    "\n",
    "    df['user_cost'] = df['adjusted_user_fee_usd']\n",
    "\n",
    "    ## Stargate Bus\n",
    "    df['user_cost'] += (\n",
    "        df['amount_sent_ld_usd'] - df['amount_received_ld_usd']\n",
    "    ).fillna(0) + df['bus_fare_usd'].fillna(0)\n",
    "\n",
    "    df['operator_cost'] += (\n",
    "        df['adjusted_executor_fee_usd'].fillna(0) + df['adjusted_dvn_fee_usd'].fillna(0) + df['adjusted_bus_fee_usd'].fillna(0)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ccip\n",
      "Processing cctp\n",
      "Processing stargate_oft\n",
      "Processing stargate_bus\n",
      "Processing across\n",
      "Processing ronin\n",
      "Processing polygon\n",
      "Processing polygon_plasma\n",
      "Processing omnibridge\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"ccip\", \"cctp\", \"stargate_oft\", \"stargate_bus\", \"across\", \"ronin\", \"polygon\", \"polygon_plasma\", \"omnibridge\"]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(\"Processing\", dataset_name)\n",
    "    df = get_data(dataset_name)\n",
    "\n",
    "    add_blockchain_types(df)\n",
    "    \n",
    "    if dataset_name == \"stargate_bus\":\n",
    "        add_stargate_bus_latency(df)\n",
    "        calculate_user_and_operator_cost_stargate_bus(df)\n",
    "    else:\n",
    "        add_cctx_latency(df)\n",
    "        calculate_user_and_operator_cost(dataset_name, df)\n",
    "\n",
    "    df = df.merge(df_token_metadata[['symbol', 'address', 'blockchain']], left_on=['src_contract_address', 'src_blockchain'], right_on=['address', 'blockchain'], how='left').rename(columns={'symbol': 'src_symbol'}).drop(columns=['address', 'blockchain'])\n",
    "\n",
    "    if 'dst_contract_address' in df.columns:\n",
    "        df = df.merge(df_token_metadata[['symbol', 'address', 'blockchain']], left_on=['dst_contract_address', 'dst_blockchain'], right_on=['address', 'blockchain'], how='left').rename(columns={'symbol': 'dst_symbol'}).drop(columns=['address', 'blockchain'])\n",
    "\n",
    "    df.to_csv(f'./data/{dataset_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes as needed for the analysis\n",
    "from pandas import DataFrame\n",
    "\n",
    "# merge across, ccip, cctp, stargate_oft, stargate_bus\n",
    "datasets = [\"cctp\", \"ccip\", \"stargate_oft\", \"stargate_bus\", \"across\"]\n",
    "\n",
    "df = DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_df = pd.read_csv(f'./data/{dataset}.csv')\n",
    "\n",
    "    new_df[\"bridge\"] = dataset\n",
    "\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "df.to_csv(f'./data/grouped/all_ccc_protocols.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# merge across, cctp, staragte_oft, stargate_bus, polygon, polygon_plasma\n",
    "datasets = [\"cctp\", \"stargate_oft\", \"stargate_bus\", \"across\", \"polygon\", \"polygon_plasma\"]\n",
    "\n",
    "df = DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_df = pd.read_csv(f'./data/{dataset}.csv')\n",
    "\n",
    "    new_df[\"bridge\"] = dataset\n",
    "\n",
    "    # filter for src_blockchain or dst_blockchain == (ethereum or polygon)\n",
    "    new_df = new_df[(new_df['src_blockchain'] == 'ethereum') | (new_df['dst_blockchain'] == 'ethereum') | (new_df['src_blockchain'] == 'polygon') | (new_df['dst_blockchain'] == 'polygon')]\n",
    "\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "df.to_csv(f'./data/grouped/ethereum_polygon.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# merge ccip, ronin\n",
    "datasets = [\"ccip\", \"ronin\"]\n",
    "\n",
    "df = DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_df = pd.read_csv(f'./data/{dataset}.csv')\n",
    "\n",
    "    new_df[\"bridge\"] = dataset\n",
    "\n",
    "    # filter for src_blockchain or dst_blockchain == (ethereum or polygon)\n",
    "    new_df = new_df[(new_df['src_blockchain'] == 'ethereum') | (new_df['dst_blockchain'] == 'ethereum') | (new_df['src_blockchain'] == 'ronin') | (new_df['dst_blockchain'] == 'ronin')]\n",
    "\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "df.to_csv(f'./data/grouped/ethereum_ronin.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# merge ccip, omnibridge\n",
    "datasets = [\"ccip\", \"omnibridge\"]\n",
    "\n",
    "df = DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    new_df = pd.read_csv(f'./data/{dataset}.csv')\n",
    "\n",
    "    new_df[\"bridge\"] = dataset\n",
    "\n",
    "    # filter for src_blockchain or dst_blockchain == (ethereum or polygon)\n",
    "    new_df = new_df[(new_df['src_blockchain'] == 'ethereum') | (new_df['dst_blockchain'] == 'ethereum') | (new_df['src_blockchain'] == 'gnosis') | (new_df['dst_blockchain'] == 'gnosis')]\n",
    "\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "df.to_csv(f'./data/grouped/ethereum_gnosis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".xchaindata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
